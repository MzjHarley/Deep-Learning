{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01befecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2b4ba6",
   "metadata": {},
   "source": [
    "## 全连接层\n",
    "### 张量实现方式\n",
    "在 TensorFlow 中，要实现全连接层，只需要定义好权值张量𝑾和偏置张量𝒃，并利用TensorFlow 提供的批量矩阵相乘函数 tf.matmul()即可完成网络层的计算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a13454d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 256])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=tf.random.normal([2,784])\n",
    "w1=tf.Variable(tf.random.truncated_normal([784,256],stddev=0.1))\n",
    "b1=tf.Variable(tf.zeros([256]))\n",
    "o1=tf.nn.relu(tf.matmul(x,w1)+b1)\n",
    "o1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824177ad",
   "metadata": {},
   "source": [
    "### 层方式实现\n",
    "全连接层本质上是矩阵的相乘和相加运算，实现并不复杂。但是作为最常用的网络层之一，TensorFlow 中有更高层、使用更方便的层实现方式：  tf.keras.layers.Dense(units, activation)。通过 layer.Dense 类，只需要指定输出节点数 Units 和激活函数类型 activation 即可。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea73f55e",
   "metadata": {},
   "source": [
    "需要注意的是，输入节点数会根据第一次运算时的输入 shape 确定，同时根据输入、输出节点数自动创建并初始化权值张量𝑾和偏置张量𝒃，因此在新建类 Dense 实例时，并不会立即创建权值张量𝑾和偏置张量𝒃，而是需要调用 build 函数或者直接进行一次前向计算，才能完成网络参数的创建."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09d12c56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 512])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.random.normal([4,28*28])\n",
    "fc = tf.keras.layers.Dense(512, activation=tf.nn.relu)\n",
    "h1 = fc(x) #通过fc实例完成一次全连接层的计算，返回输出张量\n",
    "h1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19ca054",
   "metadata": {},
   "source": [
    "我们可以通过类内部的成员名 kernel 和 bias 来获取权值张量𝑾和偏置张量𝒃对象."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc8674ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([512]), TensorShape([784, 512]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc.bias.shape,fc.kernel.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b707a1f5",
   "metadata": {},
   "source": [
    "在优化参数时，需要获得网络的所有待优化的张量参数列表，可以通过类的trainable_variables 来返回待优化参数列表."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c38926f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense/kernel:0' shape=(784, 512) dtype=float32, numpy=\n",
       " array([[-0.0307861 ,  0.02505334,  0.05957434, ..., -0.03834952,\n",
       "         -0.02201273,  0.0196663 ],\n",
       "        [ 0.03959587, -0.06677919,  0.0529246 , ...,  0.03229767,\n",
       "         -0.01608704,  0.02305287],\n",
       "        [-0.00357806, -0.04588865,  0.03671522, ..., -0.00274219,\n",
       "         -0.05812096,  0.00090273],\n",
       "        ...,\n",
       "        [-0.04790237,  0.0477358 ,  0.04936173, ..., -0.04971181,\n",
       "         -0.05189843,  0.0638763 ],\n",
       "        [-0.0523259 , -0.04522353,  0.0232817 , ..., -0.05746791,\n",
       "         -0.03175919,  0.04712183],\n",
       "        [-0.05114061,  0.04155791,  0.04887301, ..., -0.04635733,\n",
       "          0.05610921, -0.04457173]], dtype=float32)>,\n",
       " <tf.Variable 'dense/bias:0' shape=(512,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc.trainable_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc819151",
   "metadata": {},
   "source": [
    "实际上，网络层除了保存了待优化张量列表 trainable_variables，还有部分层包含了不参与梯度优化的张量，如后续介绍的 Batch Normalization 层，可以通过non_trainable_variables 成员返回所有不需要优化的参数列表。如果希望获得所有参数列表，可以通过类的 variables 返回所有内部张量列表."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1117b782",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense/kernel:0' shape=(784, 512) dtype=float32, numpy=\n",
       " array([[-0.0307861 ,  0.02505334,  0.05957434, ..., -0.03834952,\n",
       "         -0.02201273,  0.0196663 ],\n",
       "        [ 0.03959587, -0.06677919,  0.0529246 , ...,  0.03229767,\n",
       "         -0.01608704,  0.02305287],\n",
       "        [-0.00357806, -0.04588865,  0.03671522, ..., -0.00274219,\n",
       "         -0.05812096,  0.00090273],\n",
       "        ...,\n",
       "        [-0.04790237,  0.0477358 ,  0.04936173, ..., -0.04971181,\n",
       "         -0.05189843,  0.0638763 ],\n",
       "        [-0.0523259 , -0.04522353,  0.0232817 , ..., -0.05746791,\n",
       "         -0.03175919,  0.04712183],\n",
       "        [-0.05114061,  0.04155791,  0.04887301, ..., -0.04635733,\n",
       "          0.05610921, -0.04457173]], dtype=float32)>,\n",
       " <tf.Variable 'dense/bias:0' shape=(512,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79a70ae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc.non_trainable_variables #对于全连接层，内部张量都参与梯度优化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a13cd8f",
   "metadata": {},
   "source": [
    "利用网络层类对象进行前向计算时，只需要调用类的_call_方法即可，即写成 fc(x)方式便可，它会自动调用类的_call_方法，在_call_方法中会自动调用 call 方法，这一设定由 TensorFlow 框架自动完成，因此用户只需要将网络层的前向计算逻辑实现在 call 方法中即可。对于全连接层类，在 call 方法中实现𝜎(𝑿@𝑾 + 𝒃)的运算逻辑，非常简单，最后返回全连接层的输出张量即可。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f80b7a",
   "metadata": {},
   "source": [
    "## 神经网络\n",
    "通过层层堆叠全连接层，保证前一层的输出节点数与当前层的输入节点数匹配，，即可堆叠出任意层数的网络。我们把这种由神经元相互连接而成的网络叫做神经网络."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74d7d45",
   "metadata": {},
   "source": [
    "### 张量实现方式\n",
    "对于多层神经网络，需要分别定义各层的权值矩阵𝑾和偏置向量𝒃。有多少个全连接层，则需要相应地定义数量相当的𝑾和𝒃，并且每层的参数只能用于对应的层，不能混淆使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f70bdf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 隐藏层 1 张量\n",
    "w1 = tf.Variable(tf.random.truncated_normal([784, 256], stddev=0.1))\n",
    "b1 = tf.Variable(tf.zeros([256]))\n",
    "# 隐藏层 2 张量\n",
    "w2 = tf.Variable(tf.random.truncated_normal([256, 128], stddev=0.1))\n",
    "b2 = tf.Variable(tf.zeros([128]))\n",
    "# 隐藏层 3 张量\n",
    "w3 = tf.Variable(tf.random.truncated_normal([128, 64], stddev=0.1))\n",
    "b3 = tf.Variable(tf.zeros([64]))\n",
    "# 输出层张量\n",
    "w4 = tf.Variable(tf.random.truncated_normal([64, 10], stddev=0.1))\n",
    "b4 = tf.Variable(tf.zeros([10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfc93d3",
   "metadata": {},
   "source": [
    "在计算时，只需要按照网络层的顺序，将上一层的输出作为当前层的输入即可，重复直至最后一层，并将输出层的输出作为网络的输出."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4397b3c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-1.1520224   0.02800251  0.04077455  1.1807173  -0.45801836  0.74087614\n",
      "  -0.62997156 -0.6039972   0.8701964  -0.72786236]\n",
      " [-1.8524578  -1.4776922   0.22549528  1.4150536  -0.8101743   0.44836786\n",
      "  -0.12109007 -0.6369011   0.34190708 -0.31170875]\n",
      " [-0.6551108  -0.5689243   0.4464636   0.935695   -1.4232173   0.2832491\n",
      "  -0.41899273 -0.53744495  0.86872536 -0.49260426]\n",
      " [-0.42790774 -0.5431154   0.21409398  1.1970259   0.52298003 -0.27145442\n",
      "  -0.9328849   0.5241511   0.06733143 -0.29931188]], shape=(4, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "with tf.GradientTape() as tape: # 梯度记录器\n",
    " # x: [b, 28*28]\n",
    " # 隐藏层 1 前向计算，[b, 28*28] => [b, 256]\n",
    " h1 = tf.nn.relu(x@w1 + b1)\n",
    " # 隐藏层 2 前向计算，[b, 256] => [b, 128]\n",
    " h2 = tf.nn.relu(h1@w2 + b2)\n",
    " # 隐藏层 3 前向计算，[b, 128] => [b, 64] \n",
    " h3 = tf.nn.relu(h2@w3 + b3)\n",
    " # 输出层前向计算，[b, 64] => [b, 10] \n",
    " h4 = h3@w4 + b4\n",
    " print(h4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d87a16c",
   "metadata": {},
   "source": [
    "在使用 TensorFlow 自动求导功能计算梯度时，需要将前向计算过程放置在tf.GradientTape()环境中，从而利用 GradientTape 对象的 gradient()方法自动求解参数的梯度，并利用 optimizers 对象更新参数。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a60bcb",
   "metadata": {},
   "source": [
    "### 层实现方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eda2771c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 10), dtype=float32, numpy=\n",
       "array([[ 0.5810528 ,  0.13246839,  0.119058  ,  0.8072974 , -0.25786677,\n",
       "         0.6725309 ,  0.03791695, -0.0383711 , -0.2510153 , -0.26235825],\n",
       "       [ 1.1825596 , -0.8525967 , -0.55998063,  0.72997564,  0.1433095 ,\n",
       "         0.06088633, -0.44098833,  0.9646764 ,  0.48161718,  0.76033294],\n",
       "       [ 0.4486311 , -0.6438426 , -0.48827866,  0.46292692, -0.39431956,\n",
       "         0.536526  , -0.04334838,  0.6948558 ,  0.5270436 , -0.62587714],\n",
       "       [ 1.7108536 , -0.52808905, -0.5854454 ,  0.65135336, -0.95732445,\n",
       "         0.8923924 , -0.08443288,  1.7131099 ,  0.63129103, -1.2806594 ]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc1 = tf.keras.layers.Dense(256, activation=tf.nn.relu) # 隐藏层 1\n",
    "fc2 = tf.keras.layers.Dense(128, activation=tf.nn.relu) # 隐藏层 2\n",
    "fc3 = tf.keras.layers.Dense(64, activation=tf.nn.relu) # 隐藏层 3\n",
    "fc4 = tf.keras.layers.Dense(10, activation=None) # 输出层\n",
    "x = tf.random.normal([4,28*28])\n",
    "h1 = fc1(x) # 通过隐藏层 1 得到输出\n",
    "h2 = fc2(h1) # 通过隐藏层 2 得到输出\n",
    "h3 = fc3(h2) # 通过隐藏层 3 得到输出\n",
    "h4 = fc4(h3) # 通过输出层得到网络输出\n",
    "h4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a7baaf",
   "metadata": {},
   "source": [
    "对于这种数据依次向前传播的网络，也可以通过 Sequential 容器封装成一个网络大类对象，调用大类的前向计算函数一次即可完成所有层的前向计算，使用起来更加方便."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7836b1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    " tf.keras.layers.Dense(256, activation=tf.nn.relu) , # 创建隐藏层 1\n",
    " tf.keras.layers.Dense(128, activation=tf.nn.relu) , # 创建隐藏层 2\n",
    " tf.keras.layers.Dense(64, activation=tf.nn.relu) , # 创建隐藏层 3\n",
    " tf.keras.layers.Dense(10, activation=None) , # 创建输出层\n",
    "])\n",
    "out = model(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee7d8ddf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 10), dtype=float32, numpy=\n",
       "array([[ 0.47004792,  0.3292418 ,  0.18572573,  0.9790394 ,  0.00144357,\n",
       "         0.90535516,  0.5625309 , -1.2372607 , -0.51175964, -0.08494966],\n",
       "       [ 0.40531605, -0.5611396 ,  0.7220759 ,  0.28085154, -0.0097964 ,\n",
       "         1.0257103 ,  0.59307504, -0.7446377 , -0.08032487, -0.8738212 ],\n",
       "       [ 0.6008719 , -0.07689157,  0.1196698 ,  0.6115551 , -0.02869617,\n",
       "         0.07558417, -0.56385547, -1.0759587 ,  0.4417197 , -1.0154778 ],\n",
       "       [ 0.01380794,  0.0092223 ,  0.05303073,  0.8372243 ,  0.34661916,\n",
       "         0.38628712,  0.34566957, -0.4173436 ,  0.5827942 , -0.61464185]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6c7d27",
   "metadata": {},
   "source": [
    "## 激活函数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0503af7c",
   "metadata": {},
   "source": [
    "### sigmoid\n",
    "将值映射到[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7232f3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([-6.       , -4.6666665, -3.3333333, -2.       , -0.6666665,\n",
       "         0.666667 ,  2.       ,  3.333334 ,  4.666667 ,  6.       ],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([0.00247264, 0.00931591, 0.03444517, 0.11920291, 0.33924365,\n",
       "        0.6607564 , 0.8807971 , 0.96555483, 0.99068403, 0.99752736],\n",
       "       dtype=float32)>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.linspace(-6.,6.,10)\n",
    "x,tf.nn.sigmoid(x) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4271434",
   "metadata": {},
   "source": [
    "## ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50da3f43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([0.      , 0.      , 0.      , 0.      , 0.      , 0.666667,\n",
       "       2.      , 3.333334, 4.666667, 6.      ], dtype=float32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.relu(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc23a611",
   "metadata": {},
   "source": [
    "## LeakyReLU\n",
    "ReLU 函数在𝑥 < 0时导数值恒为 0，也可能会造成梯度弥散现象，为了克服这个问题，LeakyReLU 函数被提出.  \n",
    "$LeakyReLU=\\begin{cases} x &,x\\geq 0 \\\\ px &,x<0\\end{cases}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e1287d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([-0.6       , -0.46666667, -0.33333334, -0.2       , -0.06666666,\n",
       "        0.666667  ,  2.        ,  3.333334  ,  4.666667  ,  6.        ],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.leaky_relu(x, alpha=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc68c76",
   "metadata": {},
   "source": [
    "其中 alpha 参数代表𝑝。tf.nn.leaky_relu 对应的类为 layers.LeakyReLU，可以通过LeakyReLU(alpha)创建 LeakyReLU 网络层，并设置𝑝参数，像 Dense 层一样将 LeakyReLU层放置在网络的合适位置。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6ed897",
   "metadata": {},
   "source": [
    "### Tanh\n",
    "将值映射到[-1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c9b4f8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([-0.99998784, -0.99982315, -0.9974579 , -0.9640276 , -0.58278286,\n",
       "        0.58278316,  0.9640276 ,  0.99745804,  0.99982315,  0.99998784],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.tanh(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689fd19f",
   "metadata": {},
   "source": [
    "### Softmax\n",
    "Softmax 函数不仅可以将输出值映射到[0,1]区间，还满足所有的输出值之和为 1 的特性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9bbc59ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([0.6590012 , 0.24243298, 0.09856589], dtype=float32)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = tf.constant([2.,1.,0.1])\n",
    "tf.nn.softmax(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f6af18",
   "metadata": {},
   "source": [
    "与 Dense 层类似，Softmax 函数也可以作为网络层类使用，通过类 layers.Softmax(axis=-1)可以方便添加 Softmax 层，其中 axis 参数指定需要进行计算的维度。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3613874",
   "metadata": {},
   "source": [
    "在 Softmax 函数的数值计算过程中，容易因输入值偏大发生数值溢出现象；在计算交叉熵时，也会出现数值溢出的问题。为了数值计算的稳定性，TensorFlow 中提供了一个统一的接口，将 Softmax 与交叉熵损失函数同时实现，同时也处理了数值不稳定的异常，一般推荐使用这些接口函数，避免分开使用 Softmax 函数与交叉熵损失函数。函数式接口为tf.keras.losses.categorical_crossentropy(y_true, y_pred, from_logits=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6566016c",
   "metadata": {},
   "source": [
    "y_true 代表了One-hot 编码后的真实标签，y_pred 表示网络的预测值，当 from_logits 设置为 True 时，y_pred 表示须为未经过 Softmax 函数的变量 z；当 from_logits 设置为 False 时，y_pred 表示为经过 Softmax 函数的输出。为了数值计算稳定性，一般设置 from_logits 为 True，此时tf.keras.losses.categorical_crossentropy 将在内部进行 Softmax 函数计算，所以不需要在模型中显式调用 Softmax 函数."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5be98179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=3.1002355>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = tf.random.normal([2,10]) # 构造输出层的输出\n",
    "y_onehot = tf.constant([1,3]) # 构造真实值\n",
    "y_onehot = tf.one_hot(y_onehot, depth=10) # one-hot 编码\n",
    "# 输出层未使用 Softmax 函数，故 from_logits 设置为 True\n",
    "# 这样 categorical_crossentropy 函数在计算损失函数前，会先内部调用 Softmax 函数\n",
    "loss = tf.keras.losses.categorical_crossentropy(y_onehot,z,from_logits=True)\n",
    "loss = tf.reduce_mean(loss) # 计算平均交叉熵损失\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fac959",
   "metadata": {},
   "source": [
    "除了函数式接口，也可以利用 losses.CategoricalCrossentropy(from_logits)类方式同时实现 Softmax 与交叉熵损失函数的计算，from_logits 参数的设置方式相同。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b9d0d7a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=3.1002355>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criteon = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "loss = criteon(y_onehot,z) # 计算损失\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8c886c",
   "metadata": {},
   "source": [
    "## 误差计算"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b5952f",
   "metadata": {},
   "source": [
    "### MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "240261e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.90097064>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o = tf.random.normal([2,10]) # 构造网络输出\n",
    "y_onehot = tf.constant([1,3]) # 构造真实值\n",
    "y_onehot = tf.one_hot(y_onehot, depth=10)\n",
    "loss = tf.keras.losses.MSE(y_onehot, o) # 计算均方差\n",
    "loss = tf.reduce_mean(loss)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2771574b",
   "metadata": {},
   "source": [
    "也可以通过层方式实现，对应的类为 keras.losses.MeanSquaredError()，和其他层的类一样，调用__call__函数即可完成前向计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "72325370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.90097064>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criteon = tf.keras.losses.MeanSquaredError()\n",
    "loss = criteon(y_onehot,o) # 计算 batch 均方差\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6d5d97",
   "metadata": {},
   "source": [
    "### Cross Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbd82bf",
   "metadata": {},
   "source": [
    "$𝐻(𝑝||𝑞) ≜ −∑𝑝(𝑖) log  𝑞(𝑖)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab1603e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=2.9137573>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = tf.random.normal([2,10]) # 构造输出层的输出\n",
    "y_onehot = tf.constant([1,3]) # 构造真实值\n",
    "y_onehot = tf.one_hot(y_onehot, depth=10) # one-hot 编码\n",
    "# 输出层未使用 Softmax 函数，故 from_logits 设置为 True\n",
    "# 这样 categorical_crossentropy 函数在计算损失函数前，会先内部调用 Softmax 函数\n",
    "loss = tf.keras.losses.categorical_crossentropy(y_onehot,z,from_logits=True)\n",
    "loss = tf.reduce_mean(loss) # 计算平均交叉熵损失\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6348a236",
   "metadata": {},
   "source": [
    "也可以通过层方式实现，对应的类为 keras.losses.CategoricalCrossentropy(from_logits)，和其他层的类一样，调用call函数即可完成前向计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8d605864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=2.9137573>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criteon = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "loss = criteon(y_onehot,z) # 计算损失\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba15960",
   "metadata": {},
   "source": [
    "## 神经网络模型 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df9ba16",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26445198",
   "metadata": {},
   "source": [
    "Yann Lecun 在 1986 年提出了卷积神经网络(Convolutional Neural Network，简称 CNN)。  \n",
    "其中比较流行的模型有用于图片分类的 AlexNet、VGG、GoogLeNet、ResNet、DenseNet 等，用于目标识别的 RCNN、Fast RCNN、Faster RCNN、Mask RCNN、YOLO、SSD 等"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a792a0",
   "metadata": {},
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff7596f",
   "metadata": {},
   "source": [
    "除了具有空间结构的图片、视频等数据外，序列信号也是非常常见的一种数据类型，其中一个最具代表性的序列信号就是文本数据。如何处理并理解文本数据是自然语言处理的一个核心问题。卷积神经网络由于缺乏 Memory 机制和处理不定长序列信号的能力，并不擅长序列信号的任务。循环神经网络(Recurrent Neural Network，简称 RNN)在 Yoshua Bengio、Jürgen Schmidhuber 等人的持续研究下，被证明非常擅长处理序列信号。  \n",
    "1997年，Jürgen Schmidhuber 提出了 LSTM 网络，作为 RNN 的变种，它较好地克服了 RNN 缺乏长期记忆、不擅长处理长序列的问题，在自然语言处理中得到了广泛的应用.  \n",
    "其他的 RNN 变种还有 GRU、双向 RNN 等。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef28dc6",
   "metadata": {},
   "source": [
    "### Attention Mechanism"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729a59ad",
   "metadata": {},
   "source": [
    "RNN 并不是自然语言处理的最终解决方案，近年来随着注意力机制(Attention Mechanism)的提出，克服了 RNN 训练不稳定、难以并行化等缺陷，在自然语言处理和图片生成等领域中逐渐崭露头角。注意力机制最初在图片分类任务上提出，但逐渐开始侵蚀NLP 各大任务。  \n",
    "2017 年，Google 提出了第一个利用纯注意力机制实现的网络模型Transformer，随后基于 Transformer 模型相继提出了一系列的用于机器翻译的注意力网络模型，如 GPT、BERT、GPT-2 等。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92f14dd",
   "metadata": {},
   "source": [
    "### GCN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af49218a",
   "metadata": {},
   "source": [
    "图片、文本等数据具有规则的空间、时间结构，称为 Euclidean Data(欧几里德数据)。卷积神经网络和循环神经网络被证明非常擅长处理这种类型的数据。而像类似于社交网络、通信网络、蛋白质分子结构等一系列的不规则空间拓扑结构的数据，它们显得力不从心。  \n",
    "2016 年，Thomas Kipf 等人基于前人在一阶近似的谱卷积算法上提出了图卷积网络(Graph Convolution Network，GCN)模型.  \n",
    "随后，一系列的网络模型相继被提出，如 GAT，EdgeConv，DeepGCN 等。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f04a3b1",
   "metadata": {},
   "source": [
    "## 实战"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8c7f013a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8c98b51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the Car Efficiency Dataset Online\n",
    "dataset_path=tf.keras.utils.get_file(\"auto-mpg.data\",\"http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data\")\n",
    "#print (dataset_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e075dc25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MPG</th>\n",
       "      <th>Cylinders</th>\n",
       "      <th>Displacement</th>\n",
       "      <th>Horsepower</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Acceleration</th>\n",
       "      <th>Model Year</th>\n",
       "      <th>Origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693.0</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    MPG  Cylinders  Displacement  Horsepower  Weight  Acceleration  \\\n",
       "0  18.0          8         307.0       130.0  3504.0          12.0   \n",
       "1  15.0          8         350.0       165.0  3693.0          11.5   \n",
       "2  18.0          8         318.0       150.0  3436.0          11.0   \n",
       "3  16.0          8         304.0       150.0  3433.0          12.0   \n",
       "4  17.0          8         302.0       140.0  3449.0          10.5   \n",
       "\n",
       "   Model Year  Origin  \n",
       "0          70       1  \n",
       "1          70       1  \n",
       "2          70       1  \n",
       "3          70       1  \n",
       "4          70       1  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read datasets with pandas\n",
    "column_names = ['MPG','Cylinders','Displacement','Horsepower','Weight','Acceleration', 'Model Year', 'Origin']\n",
    "raw_dataset = pd.read_csv(dataset_path, names=column_names,na_values = \"?\", comment='\\t',sep=\" \", skipinitialspace=True)\n",
    "dataset = raw_dataset.copy()\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6912fbf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(398, 8)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d96f748e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MPG             0\n",
       "Cylinders       0\n",
       "Displacement    0\n",
       "Horsepower      6\n",
       "Weight          0\n",
       "Acceleration    0\n",
       "Model Year      0\n",
       "Origin          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isna().sum() # Count blank data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3660a2cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MPG             0\n",
       "Cylinders       0\n",
       "Displacement    0\n",
       "Horsepower      0\n",
       "Weight          0\n",
       "Acceleration    0\n",
       "Model Year      0\n",
       "Origin          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.dropna() # delete rows with blank data\n",
    "dataset.isna().sum() # Count blank data again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "183825b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(392, 8)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0b280814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MPG</th>\n",
       "      <th>Cylinders</th>\n",
       "      <th>Displacement</th>\n",
       "      <th>Horsepower</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Acceleration</th>\n",
       "      <th>Model Year</th>\n",
       "      <th>USA</th>\n",
       "      <th>Europe</th>\n",
       "      <th>Japan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>27.0</td>\n",
       "      <td>4</td>\n",
       "      <td>140.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>2790.0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>82</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>44.0</td>\n",
       "      <td>4</td>\n",
       "      <td>97.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2130.0</td>\n",
       "      <td>24.6</td>\n",
       "      <td>82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>32.0</td>\n",
       "      <td>4</td>\n",
       "      <td>135.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>2295.0</td>\n",
       "      <td>11.6</td>\n",
       "      <td>82</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>28.0</td>\n",
       "      <td>4</td>\n",
       "      <td>120.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>2625.0</td>\n",
       "      <td>18.6</td>\n",
       "      <td>82</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>31.0</td>\n",
       "      <td>4</td>\n",
       "      <td>119.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>2720.0</td>\n",
       "      <td>19.4</td>\n",
       "      <td>82</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      MPG  Cylinders  Displacement  Horsepower  Weight  Acceleration  \\\n",
       "393  27.0          4         140.0        86.0  2790.0          15.6   \n",
       "394  44.0          4          97.0        52.0  2130.0          24.6   \n",
       "395  32.0          4         135.0        84.0  2295.0          11.6   \n",
       "396  28.0          4         120.0        79.0  2625.0          18.6   \n",
       "397  31.0          4         119.0        82.0  2720.0          19.4   \n",
       "\n",
       "     Model Year  USA  Europe  Japan  \n",
       "393          82  1.0     0.0    0.0  \n",
       "394          82  0.0     1.0    0.0  \n",
       "395          82  1.0     0.0    0.0  \n",
       "396          82  1.0     0.0    0.0  \n",
       "397          82  1.0     0.0    0.0  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "origin = dataset.pop('Origin')\n",
    "# 根据 origin 列来写入新的 3 个列\n",
    "dataset['USA'] = (origin == 1)*1.0\n",
    "dataset['Europe'] = (origin == 2)*1.0\n",
    "dataset['Japan'] = (origin == 3)*1.0\n",
    "dataset.tail() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "89585216",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset.sample(frac=0.8,random_state=0) #Randomly select 80% of the data as the training set\n",
    "test_dataset = dataset.drop(train_dataset.index) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8c7d0399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((392, 10), (314, 10), (78, 10))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape,train_dataset.shape,test_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "df1e941e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train_dataset.pop('MPG')\n",
    "test_labels = test_dataset.pop('MPG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4d33741e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((314, 9), (314,), (78, 9), (78,))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.shape,train_labels.shape,test_dataset.shape,test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "633991a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Cylinders</th>\n",
       "      <td>314.0</td>\n",
       "      <td>5.477707</td>\n",
       "      <td>1.699788</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.00</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Displacement</th>\n",
       "      <td>314.0</td>\n",
       "      <td>195.318471</td>\n",
       "      <td>104.331589</td>\n",
       "      <td>68.0</td>\n",
       "      <td>105.50</td>\n",
       "      <td>151.0</td>\n",
       "      <td>265.75</td>\n",
       "      <td>455.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Horsepower</th>\n",
       "      <td>314.0</td>\n",
       "      <td>104.869427</td>\n",
       "      <td>38.096214</td>\n",
       "      <td>46.0</td>\n",
       "      <td>76.25</td>\n",
       "      <td>94.5</td>\n",
       "      <td>128.00</td>\n",
       "      <td>225.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weight</th>\n",
       "      <td>314.0</td>\n",
       "      <td>2990.251592</td>\n",
       "      <td>843.898596</td>\n",
       "      <td>1649.0</td>\n",
       "      <td>2256.50</td>\n",
       "      <td>2822.5</td>\n",
       "      <td>3608.00</td>\n",
       "      <td>5140.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Acceleration</th>\n",
       "      <td>314.0</td>\n",
       "      <td>15.559236</td>\n",
       "      <td>2.789230</td>\n",
       "      <td>8.0</td>\n",
       "      <td>13.80</td>\n",
       "      <td>15.5</td>\n",
       "      <td>17.20</td>\n",
       "      <td>24.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model Year</th>\n",
       "      <td>314.0</td>\n",
       "      <td>75.898089</td>\n",
       "      <td>3.675642</td>\n",
       "      <td>70.0</td>\n",
       "      <td>73.00</td>\n",
       "      <td>76.0</td>\n",
       "      <td>79.00</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USA</th>\n",
       "      <td>314.0</td>\n",
       "      <td>0.624204</td>\n",
       "      <td>0.485101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Europe</th>\n",
       "      <td>314.0</td>\n",
       "      <td>0.178344</td>\n",
       "      <td>0.383413</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Japan</th>\n",
       "      <td>314.0</td>\n",
       "      <td>0.197452</td>\n",
       "      <td>0.398712</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              count         mean         std     min      25%     50%  \\\n",
       "Cylinders     314.0     5.477707    1.699788     3.0     4.00     4.0   \n",
       "Displacement  314.0   195.318471  104.331589    68.0   105.50   151.0   \n",
       "Horsepower    314.0   104.869427   38.096214    46.0    76.25    94.5   \n",
       "Weight        314.0  2990.251592  843.898596  1649.0  2256.50  2822.5   \n",
       "Acceleration  314.0    15.559236    2.789230     8.0    13.80    15.5   \n",
       "Model Year    314.0    75.898089    3.675642    70.0    73.00    76.0   \n",
       "USA           314.0     0.624204    0.485101     0.0     0.00     1.0   \n",
       "Europe        314.0     0.178344    0.383413     0.0     0.00     0.0   \n",
       "Japan         314.0     0.197452    0.398712     0.0     0.00     0.0   \n",
       "\n",
       "                  75%     max  \n",
       "Cylinders        8.00     8.0  \n",
       "Displacement   265.75   455.0  \n",
       "Horsepower     128.00   225.0  \n",
       "Weight        3608.00  5140.0  \n",
       "Acceleration    17.20    24.8  \n",
       "Model Year      79.00    82.0  \n",
       "USA              1.00     1.0  \n",
       "Europe           0.00     1.0  \n",
       "Japan            0.00     1.0  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stats = train_dataset.describe().transpose()\n",
    "train_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1fcf07ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((314, 9), (314,), (78, 9), (78,))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def norm(x):\n",
    "    return (x - train_stats['mean']) / train_stats['std']\n",
    "normed_train_data = norm(train_dataset)\n",
    "normed_test_data = norm(test_dataset)\n",
    "normed_train_data.shape,train_labels.shape,normed_test_data.shape, test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "43009c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_db = tf.data.Dataset.from_tensor_slices((normed_train_data.values, train_labels.values))\n",
    "train_db = train_db.shuffle(100).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c329d71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.fc1 = tf.keras.layers.Dense(64, activation='relu')\n",
    "        self.fc2 = tf.keras.layers.Dense(64, activation='relu')\n",
    "        self.fc3 = tf.keras.layers.Dense(1)\n",
    "    def call(self, inputs, training=None, mask=None):\n",
    "        x = self.fc1(inputs)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2a5e06b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"network\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              multiple                  640       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             multiple                  4160      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             multiple                  65        \n",
      "=================================================================\n",
      "Total params: 4,865\n",
      "Trainable params: 4,865\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "over\n"
     ]
    }
   ],
   "source": [
    "model = Network()\n",
    "model.build(input_shape=(1, 9)) #Complete the creation of internal tensors through the build function\n",
    "model.summary()\n",
    "optimizer = tf.keras.optimizers.Adam() \n",
    "losses=[]\n",
    "for epoch in range(200): \n",
    "    for step, (x,y) in enumerate(train_db):\n",
    "        with tf.GradientTape() as tape:\n",
    "            out = model(x)\n",
    "            loss = tf.reduce_mean(tf.keras.losses.MSE(y, out))\n",
    "        if step % 10 == 0: \n",
    "            losses.append(loss)\n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "print(\"over\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a5c8a1bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(1, 201), losses, color='b', label='loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:code] *",
   "language": "python",
   "name": "conda-env-code-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
