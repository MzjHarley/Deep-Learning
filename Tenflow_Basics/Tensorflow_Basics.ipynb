{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# TensorFlow基础"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.layers as layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据类型\n",
    "\n",
    "### 数值类型\n",
    "\n",
    "标量在 TensorFlow 是如何创建的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(float, tensorflow.python.framework.ops.EagerTensor, True, 0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# python 语言方式创建标量\n",
    "a = 1.2 \n",
    "# TF 方式创建标量\n",
    "aa = tf.constant(1.2)\n",
    "\n",
    "type(a), type(aa), tf.is_tensor(aa),aa.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果要使用 TensorFlow 提供的功能函数， 须通过 TensorFlow 规定的方式去创建张量，而不能使用 Python 语言的标准变量创建方式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([1. , 2. , 3.3], dtype=float32)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.constant([1,2.,3.3])\n",
    "# 打印 TF 张量的相关信息                \n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1. , 2. , 3.3], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将 TF 张量的数据导出为 numpy 数组格式\n",
    "x.numpy() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "与标量不同，向量的定义须通过 List 容器传给 tf.constant()函数。\n",
    "\n",
    "创建一个元素的向量："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.2], dtype=float32)>,\n",
       " TensorShape([1]),\n",
       " 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建一个元素的向量\n",
    "a = tf.constant([1.2]) \n",
    "a, a.shape,a.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建 3 个元素的向量："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3,), dtype=float32, numpy=array([1., 2., 3.], dtype=float32)>,\n",
       " TensorShape([3]),\n",
       " 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # 创建 3 个元素的向量\n",
    "a = tf.constant([1,2, 3.])\n",
    "a, a.shape,a.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       " array([[1, 2],\n",
       "        [3, 4]])>,\n",
       " TensorShape([2, 2]),\n",
       " 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建 2 行 2 列的矩阵\n",
    "a = tf.constant([[1,2],[3,4]]) \n",
    "a, a.shape,a.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "三维张量可以定义为："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 2), dtype=int32, numpy=\n",
       "array([[[1, 2],\n",
       "        [3, 4]],\n",
       "\n",
       "       [[5, 6],\n",
       "        [7, 8]]])>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建 3 维张量\n",
    "tf.constant([[[1,2],[3,4]],[[5,6],[7,8]]]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 字符串类型\n",
    "\n",
    "通过传入字符串对象即可创建字符串类型的张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'Hello, Deep Learning.'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建字符串\n",
    "a = tf.constant('Hello, Deep Learning.') \n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在 tf.strings 模块中，提供了常见的字符串类型的工具函数，如小写化 lower()、 拼接\n",
    "join()、 长度 length()、 切分 split()等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'hello, deep learning.'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 小写化字符串\n",
    "tf.strings.lower(a) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 布尔类型\n",
    "布尔类型的张量只需要传入 Python 语言的布尔类型数据，转换成 TensorFlow 内部布尔型即可。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=bool, numpy=True>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建布尔类型标量\n",
    "tf.constant(True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建布尔类型的向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=bool, numpy=array([ True, False])>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # 创建布尔类型向量\n",
    "tf.constant([True, False])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "需要注意的是， TensorFlow 的布尔类型和 Python 语言的布尔类型并不等价，不能通用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=bool, numpy=True>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建 TF 布尔张量\n",
    "a = tf.constant(True) \n",
    "# TF 布尔类型张量与 python 布尔类型比较\n",
    "print(a is True)\n",
    "# 仅数值比较\n",
    "a == True "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数值精度\n",
    "\n",
    "在创建张量时，可以指定张量的保存精度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int16, numpy=-13035>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建指定精度的张量\n",
    "tf.constant(123456789, dtype=tf.int16)#overflow,get wrong result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=123456789>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(123456789, dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于浮点数， 高精度的张量可以表示更精准的数据，例如采用 tf.float32 精度保存π时，实际保存的数据为 3.1415927"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=3.1415927>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# 从 numpy 中导入 pi 常量\n",
    "np.pi \n",
    "# 32 位\n",
    "tf.constant(np.pi, dtype=tf.float32) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果采用 tf.float64 精度保存π，则能获得更高的精度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=3.141592653589793>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(np.pi, dtype=tf.float64) # 64 位"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取精度\n",
    "\n",
    "通过访问张量的 dtype 成员属性可以判断张量的保存精度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before: <dtype: 'float16'>\n",
      "after : <dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant(np.pi, dtype=tf.float16)\n",
    "\n",
    "# 读取原有张量的数值精度\n",
    "print('before:',a.dtype) \n",
    "# 如果精度不符合要求，则进行转换\n",
    "if a.dtype != tf.float32: \n",
    "    # tf.cast 函数可以完成精度转换\n",
    "    a = tf.cast(a,tf.float32) \n",
    "# 打印转换后的精度\n",
    "print('after :',a.dtype) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 类型转换\n",
    "系统的每个模块使用的数据类型、 数值精度可能各不相同， 对于不符合要求的张量的类型及精度， 需要通过 tf.cast 函数进行转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=3.140625>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建 tf.float16 低精度张量\n",
    "a = tf.constant(np.pi, dtype=tf.float16) \n",
    "# 转换为高精度张量\n",
    "tf.cast(a, tf.double) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "进行类型转换时，需要保证转换操作的合法性， 例如将高精度的张量转换为低精度的张量时，可能发生数据溢出隐患："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int16, numpy=-13035>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.constant(123456789, dtype=tf.int32)\n",
    "# 转换为低精度整型\n",
    "tf.cast(a, tf.int16) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "布尔类型与整型之间相互转换也是合法的， 是比较常见的操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 0])>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.constant([True, False])\n",
    "# 布尔类型转整型\n",
    "tf.cast(a, tf.int32) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一般默认 0 表示 False， 1 表示 True，在 TensorFlow 中，将非 0 数字都视为 True，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=bool, numpy=array([ True, False,  True,  True])>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.constant([-1, 0, 1, 2])\n",
    "# 整型转布尔类型\n",
    "tf.cast(a, tf.bool) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 待优化张量\n",
    "\n",
    "TensorFlow 增加了一种专门的数据类型来支持梯度信息的记录： tf.Variable。 tf.Variable 类型在普通的张量类型基础上添加了 name， trainable 等属性来支持计算图的构建。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Variable:0', True)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建 TF 张量\n",
    "a = tf.constant([-1, 0, 1, 2]) \n",
    "# 转换为 Variable 类型\n",
    "aa = tf.Variable(a) \n",
    "# Variable 类型张量的属性\n",
    "aa.name, aa.trainable "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "name 属性用于命名计算图中的变量，这套命名体系是 TensorFlow 内部维护的， 一般不需要用户关注 name 属性；   \n",
    "trainable属性表征当前张量是否需要被优化，创建 Variable 对象时是默认启用优化标志，可以设置trainable=False 来设置张量不需要优化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2, 2) dtype=int32, numpy=\n",
       "array([[1, 2],\n",
       "       [3, 4]])>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 直接创建 Variable 张量\n",
    "tf.Variable([[1,2],[3,4]]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "待优化张量可视为普通张量的特殊类型，普通张量其实也可以通过 GradientTape.watch()方法临时加入跟踪梯度信息的列表，从而支持自动求导功能"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建张量\n",
    "\n",
    "### 从数组、列表对象创建"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过 tf.convert_to_tensor 函数可以创建新 Tensor，并将保存在 Python List 对象或者Numpy Array 对象中的数据导入到新 Tensor 中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([1., 2.], dtype=float32)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 从列表创建张量\n",
    "tf.convert_to_tensor([1,2.]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float64, numpy=\n",
       "array([[1., 2.],\n",
       "       [3., 4.]])>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 从数组中创建张量\n",
    "tf.convert_to_tensor(np.array([[1,2.],[3,4]])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建全0或全1张量\n",
    "tf.zeros(shape）,tf.ones(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=0.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建全 0，全 1 的标量\n",
    "tf.zeros([]),tf.ones([]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建全 0，全 1 的向量\n",
    "tf.zeros([1]),tf.ones([1]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建全 0 的矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[0., 0.],\n",
       "       [0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建全 0 矩阵，指定 shape 为 2 行 2 列\n",
    "tf.zeros([2,2]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建全 1 的矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建全 1 矩阵，指定 shape 为 3 行 2 列\n",
    "tf.ones([3,2]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过 tf.zeros_like, tf.ones_like 可以方便地新建与某个张量 shape 一致， 且内容为全 0 或全 1 的张量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[0., 0., 0.],\n",
       "       [0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建一个矩阵\n",
    "a = tf.ones([2,3]) \n",
    "# 创建一个与 a 形状相同，但是全 0 的新矩阵\n",
    "tf.zeros_like(a) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建与张量A形状一样的全 1 张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[1., 1.],\n",
       "       [1., 1.],\n",
       "       [1., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建一个矩阵\n",
    "a = tf.zeros([3,2]) \n",
    "# 创建一个与 a 形状相同，但是全 1 的新矩阵\n",
    "tf.ones_like(a) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建自定义数值张量\n",
    "\n",
    "通过 tf.fill(shape, value)可以创建全为自定义数值 value 的张量，形状由 shape 参数指定。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=-1>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建-1 的标量\n",
    "tf.fill([], -1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=int32, numpy=array([-1])>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建-1 的向量\n",
    "tf.fill([1], -1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[99, 99],\n",
       "       [99, 99]])>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建 2 行 2 列，元素全为 99 的矩阵\n",
    "tf.fill([2,2], 99) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建已知分布的张量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过 tf.random.normal(shape, mean=0.0, stddev=1.0,dtype=tf.float32)可以创建形状为 shape，均值为mean，标准差为 stddev 的正态分布$\\mathcal{N}(mean, stddev^2)$。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[ 0.7420981, -0.6356882],\n",
       "       [ 1.32246  ,  1.0295135]], dtype=float32)>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建标准正态分布的张量\n",
    "tf.random.normal([2,2]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[-0.57465875, -3.1978993 ],\n",
       "       [-0.5521182 ,  3.4127488 ]], dtype=float32)>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建均值为 1，标准差为 2 的正态分布的张量\n",
    "tf.random.normal([2,2], mean=1,stddev=2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过 tf.random.uniform(shape, minval=0, maxval=None, dtype=tf.float32)可以创建采样自[minval, maxval)区间的均匀分布的张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[0.14379907, 0.70947576],\n",
       "       [0.09068167, 0.33488297],\n",
       "       [0.05804276, 0.21395779]], dtype=float32)>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建采样自[0,1)均匀分布的矩阵,如果是浮点数则最大值默认为1\n",
    "tf.random.uniform([3,2]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[1.8585074, 7.683893 ],\n",
       "       [7.1950245, 5.334282 ]], dtype=float32)>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建采样自[0,10)均匀分布的矩阵\n",
    "tf.random.uniform([2,2],maxval=10) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果需要均匀采样整形类型的数据，必须指定采样区间的最大值 maxval 参数，同时指定数据类型为 tf.int*型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[43, 76],\n",
       "       [16, 94]])>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建采样自[0,100)均匀分布的整型矩阵\n",
    "tf.random.uniform([2,2],maxval=100,dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建序列\n",
    "\n",
    "tf.range(limit, delta=1)可以创建[0, limit)之间，步长为 delta 的整型序列，不包含 limit 本身。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0~10，不包含 10\n",
    "tf.range(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 2, 4, 6, 8])>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建 0~10，步长为 2 的整形序列\n",
    "tf.range(10,delta=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=int32, numpy=array([1, 3, 5, 7, 9])>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.range(1,10,delta=2) # 1~10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 张量的典型应用\n",
    "\n",
    "### 标量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.32437342, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 随机模拟网络输出\n",
    "out = tf.random.uniform([4,10]) \n",
    "# 随机构造样本真实标签\n",
    "y = tf.constant([2,3,2,0]) \n",
    "# one-hot 编码\n",
    "y = tf.one_hot(y, depth=10) \n",
    "# 计算每个样本的 MSE\n",
    "loss = tf.keras.losses.mse(y, out) \n",
    "# 平均 MSE,loss 应是标量\n",
    "loss = tf.reduce_mean(loss) \n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 向量\n",
    "\n",
    "考虑 2 个输出节点的网络层， 我们创建长度为 2 的偏置向量b，并累加在每个输出节点上："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 2), dtype=float32, numpy=\n",
       "array([[ 1.7018489 ,  0.6248561 ],\n",
       "       [ 0.7025767 , -0.86812556],\n",
       "       [ 0.81105405, -0.06037486],\n",
       "       [-1.5896156 , -2.0634787 ]], dtype=float32)>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# z=wx,模拟获得激活函数的输入 z\n",
    "z = tf.random.normal([4,2])\n",
    "# 创建偏置向量\n",
    "b = tf.zeros([2])\n",
    "# 累加上偏置向量\n",
    "z = z + b \n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建输入节点数为 4，输出节点数为 3 的线性层网络，那么它的偏置向量 b 的长度应为 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'bias:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建一层 Wx+b，输出节点为 3\n",
    "fc = tf.keras.layers.Dense(3) \n",
    "# 通过 build 函数创建 W,b 张量，输入节点为 4\n",
    "fc.build(input_shape=(1,4))\n",
    "# 查看偏置向量\n",
    "fc.bias "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[ 3.4188414 ,  3.4188414 ,  3.4188414 ],\n",
       "       [-0.18239978, -0.18239978, -0.18239978]], dtype=float32)>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2 个样本，特征长度为 4 的张量\n",
    "x = tf.random.normal([2,4]) \n",
    "# 定义 W 张量\n",
    "w = tf.ones([4,3])\n",
    "# 定义 b 张量\n",
    "b = tf.zeros([3]) \n",
    "# X@W+b 运算\n",
    "o = x@w+b \n",
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-0.5909019 , -0.62288916, -0.66296035],\n",
      "       [ 0.24147391,  0.76191616, -0.24088341],\n",
      "       [ 0.69130015, -0.5228372 , -0.84390265],\n",
      "       [-0.06907368, -0.5915246 , -0.4537969 ]], dtype=float32), array([0., 0., 0.], dtype=float32)]\n",
      "[<tf.Variable 'kernel:0' shape=(4, 3) dtype=float32, numpy=\n",
      "array([[-0.5909019 , -0.62288916, -0.66296035],\n",
      "       [ 0.24147391,  0.76191616, -0.24088341],\n",
      "       [ 0.69130015, -0.5228372 , -0.84390265],\n",
      "       [-0.06907368, -0.5915246 , -0.4537969 ]], dtype=float32)>, <tf.Variable 'bias:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'kernel:0' shape=(4, 3) dtype=float32, numpy=\n",
       "array([[-0.5909019 , -0.62288916, -0.66296035],\n",
       "       [ 0.24147391,  0.76191616, -0.24088341],\n",
       "       [ 0.69130015, -0.5228372 , -0.84390265],\n",
       "       [-0.06907368, -0.5915246 , -0.4537969 ]], dtype=float32)>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 定义全连接层的输出节点为 3\n",
    "fc = tf.keras.layers.Dense(3) \n",
    "# 定义全连接层的输入节点为 4\n",
    "fc.build(input_shape=(2,4)) \n",
    "print(fc.get_weights())\n",
    "print(fc.weights)\n",
    "# 查看权值矩阵 W\n",
    "fc.kernel "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 三维张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 80)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 自动加载 IMDB 电影评价数据集\n",
    "(x_train,y_train),(x_test,y_test)=keras.datasets.imdb.load_data(num_words=10000)#将数据限定为前10000个最常出现的单词，不经常出现的单词被抛弃\n",
    "# 将句子填充、截断为等长 80 个单词的句子\n",
    "x_train = keras.preprocessing.sequence.pad_sequences(x_train,maxlen=80)#maxlen：None或整数，为序列的最大长度。大于此长度的将被截断，小于此长度的序列将在后面填0.\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到 x_train 张量的 shape 为[25000,80]，其中 25000 表示句子个数， 80 表示每个句子共 80 个单词，每个单词使用数字编码方式表示。\n",
    "\n",
    "我们通过 layers.Embedding 层将数字编码的单词转换为长度为 100 个词向量："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([25000, 80, 100])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建词向量 Embedding 层类\n",
    "embedding = tf.keras.layers.Embedding(10000, 100) #10000个单词，每个单词转换成长度为100的向量\n",
    "# 将数字编码的单词转换为词向量\n",
    "out = embedding(x_train)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到，经过 Embedding 层编码后，句子张量的 shape 变为[25000,80,100]，其中 100 表示每个单词编码为长度是 100 的向量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 四维张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 30, 30, 16])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建 32x32 的彩色图片输入，个数为 4\n",
    "x = tf.random.normal([4,32,32,3])\n",
    "# 创建卷积神经网络\n",
    "layer = layers.Conv2D(16, kernel_size=3)#[3,3,3]这样的卷积核有16个，因此经过卷积层后，会得到4个16通道30*30的矩阵。\n",
    "# 前向计算\n",
    "out = layer(x)\n",
    "# 输出大小\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 3, 3, 16])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 访问卷积核张量\n",
    "layer.kernel.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 索引与切片\n",
    "### 索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建4维张量\n",
    "x = tf.random.normal([4,32,32,3]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 32, 3])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 取第 1 张图片的数据\n",
    "x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 3])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 取第 1 张图片的第 2 行\n",
    "x[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 取第 1 张图片，第 2 行，第 3 列的数据\n",
    "x[0][1][2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 取第 3 张图片，第 2 行，第 1 列的像素， B 通道(第 2 个通道)颜色强度值\n",
    "x[2][1][0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 取第 2 张图片，第 10 行，第 3 列的数据\n",
    "x[1,9,2].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 切片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 32, 32, 3])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取第 2,3 张图片\n",
    "x[1:3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 32, 3])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取第一张图片\n",
    "x[0,::].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 14, 14, 3])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:,0:28:2,0:28:2,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8,), dtype=int32, numpy=array([8, 7, 6, 5, 4, 3, 2, 1])>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 考虑一个 0~9 的简单序列向量， 逆序取到第 1 号元素，不包含第 1 号\n",
    "# 创建 0~9 向量\n",
    "x = tf.range(9) \n",
    "# 从 8 取到 0，逆序，不包含 0\n",
    "x[8:0:-1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(9,), dtype=int32, numpy=array([8, 7, 6, 5, 4, 3, 2, 1, 0])>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 逆序全部元素\n",
    "x[::-1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=int32, numpy=array([8, 6, 4, 2, 0])>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 逆序间隔采样\n",
    "x[::-2] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读取每张图片的所有通道，其中行按着逆序隔行采样，列按着逆序隔行采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([16, 16, 3])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.random.normal([4,32,32,3])\n",
    "# 行、列逆序间隔采样\n",
    "x[0,::-2,::-2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 32, 32])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 取 G 通道数据\n",
    "x[:,:,:,1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 32, 32, 2])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取第 1~2 张图片的 G/B 通道数据\n",
    "# 高宽维度全部采集\n",
    "x[0:2,...,1:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 32, 32, 3])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取最后 2 张图片\n",
    "# 高、宽、通道维度全部采集，等价于 x[2:]\n",
    "x[2:,...].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 32, 32, 2])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取 R/G 通道数据\n",
    "# 所有样本，所有高、宽的前 2 个通道\n",
    "x[...,:2].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 维度变换"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 改变视图"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们通过 tf.range()模拟生成一个向量数据，并通过 tf.reshape 视图改变函数产生不同的视图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23], shape=(24,), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1, 4, 3), dtype=int32, numpy=\n",
       "array([[[[ 0,  1,  2],\n",
       "         [ 3,  4,  5],\n",
       "         [ 6,  7,  8],\n",
       "         [ 9, 10, 11]]],\n",
       "\n",
       "\n",
       "       [[[12, 13, 14],\n",
       "         [15, 16, 17],\n",
       "         [18, 19, 20],\n",
       "         [21, 22, 23]]]])>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 生成向量\n",
    "x = tf.range(24) \n",
    "print(x)\n",
    "# 改变 x 的视图，获得 4D 张量，存储并未改变\n",
    "x = tf.reshape(x,[2,1,4,3]) \n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, TensorShape([2, 1, 4, 3]))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 获取张量的维度数和形状列表\n",
    "x.ndim,x.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(24,), dtype=int32, numpy=\n",
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23])>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reshape(x,[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过 tf.reshape(x, new_shape)，可以将张量的视图任意地合法改变"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 12), dtype=int32, numpy=\n",
       "array([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11],\n",
       "       [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]])>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reshape(x,[2,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3, 4), dtype=int32, numpy=\n",
       "array([[[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11]],\n",
       "\n",
       "       [[12, 13, 14, 15],\n",
       "        [16, 17, 18, 19],\n",
       "        [20, 21, 22, 23]]])>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " tf.reshape(x,[2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 4, 3), dtype=int32, numpy=\n",
       "array([[[ 0,  1,  2],\n",
       "        [ 3,  4,  5],\n",
       "        [ 6,  7,  8],\n",
       "        [ 9, 10, 11]],\n",
       "\n",
       "       [[12, 13, 14],\n",
       "        [15, 16, 17],\n",
       "        [18, 19, 20],\n",
       "        [21, 22, 23]]])>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reshape(x,[2,-1,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 增、删维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([28, 28])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 产生矩阵\n",
    "x = tf.random.uniform([28,28],maxval=10,dtype=tf.int32)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过 tf.expand_dims(x, axis)可在指定的 axis 轴前可以插入一个新的维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([28, 28, 1])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# axis=2 表示宽维度后面的一个维度\n",
    "x = tf.expand_dims(x,axis=2) \n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 28, 28, 1])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.expand_dims(x,axis=0) # 高维度之前插入新维度\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([28, 28, 1])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.squeeze(x, axis=0) # 删除图片数量维度\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([28, 28])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.random.uniform([1,28,28,1],maxval=10,dtype=tf.int32)\n",
    "x=tf.squeeze(x) # 如果不指定维度参数 axis，那么它会默认删除所有长度为 1 的维度\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 交换维度\n",
    "如在 TensorFlow 中，图片张量的默认存储格式是通道后行格式：[𝑏,ℎ,w,𝑐]，但是部分库的图片格式是通道先行格式：[𝑏,𝑐,ℎ,w]，因此需要完成[𝑏,ℎ,w,𝑐]到[𝑏,𝑐,ℎ,w]维度交换运算，此时若简单的使用改变视图函数 reshape，则新视图的存储方式需要改变，因此使用改变视图函数是不合法的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 3, 32, 32])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.random.normal([2,32,32,3])\n",
    "# 交换维度\n",
    "x=tf.transpose(x,perm=[0,3,1,2]) #参数 perm表示新维度的顺序 List,为index列表\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 复制数据\n",
    "当通过增加维度操作插入新维度后，可能希望在**新的维度上**面复制若干份数据，满足后续算法的格式要求。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2), dtype=int32, numpy=array([[1, 2]])>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建向量 b\n",
    "b = tf.constant([1,2]) \n",
    "# 插入新维度，变成矩阵\n",
    "b = tf.expand_dims(b, axis=0) \n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 4), dtype=int32, numpy=\n",
       "array([[1, 2, 1, 2],\n",
       "       [1, 2, 1, 2],\n",
       "       [1, 2, 1, 2]])>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 样本维度上复制一份\n",
    "b = tf.tile(b, multiples=[3,2]) #multiples 分别指定了每个维度上面的复制倍数，对应位置为 1 表明不复制，为 2 表明新长度为原来长度的2 倍，即数据复制一份，以此类推\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[0, 1],\n",
       "       [2, 3]])>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.range(4)\n",
    "# 创建 2 行 2 列矩阵\n",
    "x=tf.reshape(x,[2,2]) \n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 4), dtype=int32, numpy=\n",
       "array([[0, 1, 0, 1],\n",
       "       [2, 3, 2, 3]])>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 列维度复制一份\n",
    "x = tf.tile(x,multiples=[1,2]) \n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 4), dtype=int32, numpy=\n",
       "array([[0, 1, 0, 1],\n",
       "       [2, 3, 2, 3],\n",
       "       [0, 1, 0, 1],\n",
       "       [2, 3, 2, 3]])>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 行维度复制一份\n",
    "x = tf.tile(x,multiples=[2,1]) \n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8, 8), dtype=int32, numpy=\n",
       "array([[0, 1, 0, 1, 0, 1, 0, 1],\n",
       "       [2, 3, 2, 3, 2, 3, 2, 3],\n",
       "       [0, 1, 0, 1, 0, 1, 0, 1],\n",
       "       [2, 3, 2, 3, 2, 3, 2, 3],\n",
       "       [0, 1, 0, 1, 0, 1, 0, 1],\n",
       "       [2, 3, 2, 3, 2, 3, 2, 3],\n",
       "       [0, 1, 0, 1, 0, 1, 0, 1],\n",
       "       [2, 3, 2, 3, 2, 3, 2, 3]])>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.tile(x,multiples=[2,2]) \n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Broadcasting\n",
    "Broadcasting 称为广播机制(或自动扩展机制)，它是一种轻量级的张量复制手段，在逻辑上扩展张量数据的形状，但是只会在需要时才会执行实际存储复制操作。对于大部分场景，Broadcasting 机制都能通过优化手段避免实际复制数据而完成逻辑运算，从而相对于tf.tile 函数，减少了大量计算代价。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 32, 32, 3])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建矩阵\n",
    "A = tf.random.normal([32,1]) \n",
    "# 扩展为 4D 张量\n",
    "A=tf.broadcast_to(A, [2,32,32,3]) #[32,1]->[32,3]->[32,32,3]->[2,32,32,3]\n",
    "A.shape\n",
    "#print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incompatible shapes: [32,2] vs. [2,32,32,4] [Op:BroadcastTo]\n"
     ]
    }
   ],
   "source": [
    "A = tf.random.normal([32,2])\n",
    "# 不符合 Broadcasting 条件,不满足普适性\n",
    "try: \n",
    "    tf.broadcast_to(A, [2,32,32,4])\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数学运算\n",
    "\n",
    "### 加、减、乘、除运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 0, 1, 1, 2])>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.range(5)\n",
    "b = tf.constant(2)\n",
    "# 整除运算\n",
    "a//b "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 1, 0, 1, 0])>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 余除运算\n",
    "a%b "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 乘方运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([ 0,  1,  8, 27])>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.range(4)\n",
    "# 乘方运算\n",
    "tf.pow(x,3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([0, 1, 4, 9])>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 乘方运算符\n",
    "x**2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([1., 2., 3.], dtype=float32)>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=tf.constant([1.,4.,9.])\n",
    "# 平方根\n",
    "x**(0.5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=float32, numpy=array([ 0.,  1.,  4.,  9., 16.], dtype=float32)>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.range(5)\n",
    "# 转换为浮点数\n",
    "x = tf.cast(x, dtype=tf.float32) \n",
    "# 平方\n",
    "x = tf.square(x) \n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=float32, numpy=\n",
       "array([0.        , 0.99999994, 1.9999999 , 2.9999998 , 4.        ],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 平方根\n",
    "tf.sqrt(x) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 指数和对数运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([2., 4., 8.], dtype=float32)>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.constant([1.,2.,3.])\n",
    "# 指数运算\n",
    "2**x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=2.7182817>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 自然指数运算\n",
    "tf.exp(1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(20.085537, shape=(), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=3.0>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.exp(3.)\n",
    "print(x)\n",
    "# 对数运算\n",
    "tf.math.log(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([1., 2.], dtype=float32)>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.constant([1.,2.])\n",
    "x = 10**x\n",
    "# 换底公式\n",
    "tf.math.log(x)/tf.math.log(10.) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 矩阵相乘运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 3, 28, 2])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.random.normal([4,3,28,32])\n",
    "b = tf.random.normal([4,3,32,2])\n",
    "# 批量形式的矩阵相乘\n",
    "(a@b).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 28, 16])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.random.normal([4,28,32])\n",
    "b = tf.random.normal([32,16])\n",
    "# 先自动扩展，再矩阵相乘\n",
    "tf.matmul(a,b).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "273.188px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
